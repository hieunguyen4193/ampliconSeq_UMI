{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d941f744",
   "metadata": {},
   "source": [
    "# Overview: checking metadata and samplesheet for all RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da652c79",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4510d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All available runs: R7288, R7297, R7312, R7331, R7347, R7353, R7373, R7374, R7393, R7400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import pathlib\n",
    "import pysam\n",
    "import pyfaidx\n",
    "import warnings\n",
    "import re\n",
    "import argparse\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "main_outptudir = \"/workdir/outdir/pipeline_output\"\n",
    "umt_distance = 0\n",
    "analysis_output_version = \"20250614\"\n",
    "name = \"Truong\"\n",
    "\n",
    "path_to_main_output = os.path.join(main_outptudir, \"data_analysis\", name, analysis_output_version)\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\")\n",
    "os.system(f\"mkdir -p {path_to_01_output}\")\n",
    "\n",
    "rundf = pd.read_excel(\"../panel_design/All_panel_designs_20250601.xlsx\", sheet_name=\"Runs_tracking\")\n",
    "rundf.columns = [\"Run\", \"SampleID\", \"UMI\", \"Panel_version\", \"Name\", \"amplicon_name\", \"serial\"]\n",
    "\n",
    "umi_rundf = rundf[(rundf[\"UMI\"] == \"Yes\") & (rundf[\"Name\"] == name) ]\n",
    "\n",
    "collect_all_sample_sheets = [item for item in pathlib.Path(\"../experiments/\").glob(\"SampleSheet_batch_*.csv\")]\n",
    "\n",
    "samplesheet = pd.DataFrame()\n",
    "for file in collect_all_sample_sheets:\n",
    "    df = pd.read_csv(file, sep=\",\")\n",
    "    df[\"batch\"] = file.name.replace(\".csv\", \"\")\n",
    "    samplesheet = pd.concat([samplesheet, df], ignore_index=True)\n",
    "\n",
    "samplesheet.columns = [\"filename\", \"FASTQ1\", \"FASTQ2\", \"batch\"]\n",
    "samplesheet[\"Run\"] = samplesheet[\"FASTQ1\"].apply(lambda x: x.split(\"/\")[5] if x.split(\"/\")[5] != \"2025\" else x.split(\"/\")[6])\n",
    "samplesheet[\"SampleID\"] = samplesheet[\"filename\"].apply(lambda x: x.split(\"_\")[0].split(\"-\")[1])\n",
    "print(f\"All available runs: {\", \".join(sorted(samplesheet['Run'].unique()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7ad60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>FASTQ1</th>\n",
       "      <th>FASTQ2</th>\n",
       "      <th>batch</th>\n",
       "      <th>Run</th>\n",
       "      <th>SampleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-TMC3S1_S7583-S7783</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/10-TMC3...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/10-TMC3...</td>\n",
       "      <td>SampleSheet_batch_20250612</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMC3S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-TMC4S1_S7584-S7784</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/11-TMC4...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/11-TMC4...</td>\n",
       "      <td>SampleSheet_batch_20250612</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMC4S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-TMC5S1_S7546-S7746</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/12-TMC5...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/12-TMC5...</td>\n",
       "      <td>SampleSheet_batch_20250612</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMC5S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-TMC6S1_S7549-S7749</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/13-TMC6...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/13-TMC6...</td>\n",
       "      <td>SampleSheet_batch_20250612</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMC6S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14-TMC1S2_S7502-S7702</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/14-TMC1...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/14-TMC1...</td>\n",
       "      <td>SampleSheet_batch_20250612</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMC1S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4-TMPC4S4_S7543-S7743</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>SampleSheet_batch_20250613_smallsize</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMPC4S4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>5-TMPC3S5_S7544-S7744</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>SampleSheet_batch_20250613_smallsize</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMPC3S5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>6-TMPC3S6_S7557-S7757</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>SampleSheet_batch_20250613_smallsize</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMPC3S6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>7-TMPC3S7_S7558-S7758</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...</td>\n",
       "      <td>SampleSheet_batch_20250613_smallsize</td>\n",
       "      <td>R7393</td>\n",
       "      <td>TMPC3S7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>9-TMPL2S4_S7517-S7717</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7312/zatm/smallsi...</td>\n",
       "      <td>/mnt/GS-BACKUP05/FASTQ/2025/R7312/zatm/smallsi...</td>\n",
       "      <td>SampleSheet_batch_20250613_smallsize</td>\n",
       "      <td>R7312</td>\n",
       "      <td>TMPL2S4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                             FASTQ1  \\\n",
       "0    10-TMC3S1_S7583-S7783  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/10-TMC3...   \n",
       "1    11-TMC4S1_S7584-S7784  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/11-TMC4...   \n",
       "2    12-TMC5S1_S7546-S7746  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/12-TMC5...   \n",
       "3    13-TMC6S1_S7549-S7749  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/13-TMC6...   \n",
       "4    14-TMC1S2_S7502-S7702  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/14-TMC1...   \n",
       "..                     ...                                                ...   \n",
       "310  4-TMPC4S4_S7543-S7743  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "311  5-TMPC3S5_S7544-S7744  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "312  6-TMPC3S6_S7557-S7757  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "313  7-TMPC3S7_S7558-S7758  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "314  9-TMPL2S4_S7517-S7717  /mnt/GS-BACKUP05/FASTQ/2025/R7312/zatm/smallsi...   \n",
       "\n",
       "                                                FASTQ2  \\\n",
       "0    /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/10-TMC3...   \n",
       "1    /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/11-TMC4...   \n",
       "2    /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/12-TMC5...   \n",
       "3    /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/13-TMC6...   \n",
       "4    /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/14-TMC1...   \n",
       "..                                                 ...   \n",
       "310  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "311  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "312  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "313  /mnt/GS-BACKUP05/FASTQ/2025/R7393/zatm/smallsi...   \n",
       "314  /mnt/GS-BACKUP05/FASTQ/2025/R7312/zatm/smallsi...   \n",
       "\n",
       "                                    batch    Run SampleID  \n",
       "0              SampleSheet_batch_20250612  R7393   TMC3S1  \n",
       "1              SampleSheet_batch_20250612  R7393   TMC4S1  \n",
       "2              SampleSheet_batch_20250612  R7393   TMC5S1  \n",
       "3              SampleSheet_batch_20250612  R7393   TMC6S1  \n",
       "4              SampleSheet_batch_20250612  R7393   TMC1S2  \n",
       "..                                    ...    ...      ...  \n",
       "310  SampleSheet_batch_20250613_smallsize  R7393  TMPC4S4  \n",
       "311  SampleSheet_batch_20250613_smallsize  R7393  TMPC3S5  \n",
       "312  SampleSheet_batch_20250613_smallsize  R7393  TMPC3S6  \n",
       "313  SampleSheet_batch_20250613_smallsize  R7393  TMPC3S7  \n",
       "314  SampleSheet_batch_20250613_smallsize  R7312  TMPL2S4  \n",
       "\n",
       "[315 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e772f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R7332', 'R7393', 'R7381', 'R7400'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umi_rundf.Run.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80ab64",
   "metadata": {},
   "source": [
    "## Check if there is any missing FASTQ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8de7362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R7332', 'R7381', 'R7393', 'R7400']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_fastq = [item for item in umi_rundf.SampleID.unique() if item not in samplesheet.SampleID.unique()]\n",
    "\n",
    "sorted(umi_rundf[umi_rundf.SampleID.isin(missing_fastq)].Run.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb5f1b",
   "metadata": {},
   "source": [
    "## Match output paths to main metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5891c",
   "metadata": {},
   "source": [
    "since there is duplicated SampleID, we should merge labcode and Run together to make them unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226d925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in saved processed UMI runs tracking file...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workdir/outdir/pipeline_output/data_analysis/Vi/20250614/01_output/UMI_runs_tracking.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mreading in saved processed UMI runs tracking file...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     final_umi_rundf = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_01_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUMI_runs_tracking.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nextflow_dev/lib/python3.13/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nextflow_dev/lib/python3.13/site-packages/pandas/io/excel/_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nextflow_dev/lib/python3.13/site-packages/pandas/io/excel/_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nextflow_dev/lib/python3.13/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workdir/outdir/pipeline_output/data_analysis/Vi/20250614/01_output/UMI_runs_tracking.xlsx'"
     ]
    }
   ],
   "source": [
    "rerun = True\n",
    "if os.path.isfile(os.path.join(path_to_01_output, \"UMI_runs_tracking.xlsx\")) == False | rerun  == True:\n",
    "    umi_rundf[\"uniqueID\"] = umi_rundf[[\"SampleID\", \"Run\"]].apply(lambda x: f\"{x[0]}_{x[1]}\", axis=1)\n",
    "    samplesheet[\"uniqueID\"] = samplesheet[[\"SampleID\", \"Run\"]].apply(lambda x: f\"{x[0]}_{x[1]}\", axis=1)\n",
    "\n",
    "    final_umi_rundf = umi_rundf.merge(samplesheet.drop([\"SampleID\", \"Run\"], axis = 1), left_on = \"uniqueID\", right_on = \"uniqueID\")\n",
    "    final_umi_rundf[\"UMI_cov_file\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(lambda x: os.path.join(\n",
    "        main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_COV\", f\"{x[1]}.connor_R1_bismark_bt2_pe.bedGraph.gz.bismark.zero.cov\"\n",
    "    ), axis = 1)\n",
    "    final_umi_rundf[\"nonUMI_cov_file\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(lambda x: os.path.join(\n",
    "        main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_COV\", f\"{x[1]}.CutAdapt_R1_bismark_bt2_pe.bedGraph.gz.bismark.zero.cov\"\n",
    "    ), axis = 1)\n",
    "\n",
    "    final_umi_rundf[\"check_UMI\"] = final_umi_rundf[\"UMI_cov_file\"].apply(lambda x: os.path.exists(x))\n",
    "    final_umi_rundf[\"check_nonUMI\"] = final_umi_rundf[\"nonUMI_cov_file\"].apply(lambda x: os.path.exists(x))\n",
    "\n",
    "    final_umi_rundf[\"unmapped_bam\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_ALIGNMENT_UNMAPPED_BAM\", f\"{x[1]}_R1.UMIprocessed_bismark_bt2_pe.bam\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"connor_annotated\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"CONNOR_UMI_OUTPUT\", f\"{x[1]}.connor.fully_annotated.bam\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"connor_fastq\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"CONNOR_UMI_OUTPUT\", f\"{x[1]}.connor_R1.fastq.gz\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"umi_bam\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_ALIGNMENT\", f\"{x[1]}.connor_R1_bismark_bt2_pe.sorted.bam\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"non_umi_bam\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_ALIGNMENT\", f\"{x[1]}.CutAdapt_R1_bismark_bt2_pe.sorted.bam\"), axis = 1\n",
    "    )\n",
    "\n",
    "    tqdm.pandas()\n",
    "    for col in [\"unmapped_bam\", \"connor_annotated\", \"connor_fastq\", \"umi_bam\", \"non_umi_bam\" , \"UMI_cov_file\"]:\n",
    "        print(f\"working on column: {col}\")\n",
    "        def _get_line_count(x):\n",
    "            check_file = os.path.exists(x)\n",
    "            x_raw = x.replace(\".sorted.bam\", \".bam\")\n",
    "            if check_file == False:\n",
    "                if os.path.exists(x_raw) == True: \n",
    "                    # print(f\"sorted bam file is not available, but raw bam file is available, sorting and indexing it now...\")\n",
    "                    os.system(f\"samtools sort -@ 15 {x_raw} -o {x}\")\n",
    "                    os.system(f\"samtools index {x}\")\n",
    "                else:\n",
    "                    # rint(f\"File {x} does not exist, skipping line count for this file.\")\n",
    "                    return 0\n",
    "            if \".bam\" in x:\n",
    "                result = subprocess.run(f\"samtools view {x} -c\", shell=True, capture_output=True, text=True)\n",
    "            elif \".fastq.gz\" in x:\n",
    "                result = subprocess.run(f\"zcat {x} | wc -l\", shell=True, capture_output=True, text=True)\n",
    "            else:\n",
    "                result = subprocess.run(f\"cat {x} | wc -l\", shell=True, capture_output=True, text=True)\n",
    "            return int(result.stdout.strip())\n",
    "            \n",
    "        final_umi_rundf[f\"count_{col}\"] = final_umi_rundf[col].progress_apply(_get_line_count)    \n",
    "\n",
    "    final_umi_rundf.to_excel(os.path.join(path_to_01_output, \"UMI_runs_tracking.xlsx\"), index=False)\n",
    "else:\n",
    "    print(\"reading in saved processed UMI runs tracking file...\")\n",
    "    final_umi_rundf = pd.read_excel(os.path.join(path_to_01_output, \"UMI_runs_tracking.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f0dec",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panel_name = \"Lung_panel version 1.1\"\n",
    "# cpgdf = pd.DataFrame()\n",
    "# panel_name = panel_name.replace(\" \", \"_\")\n",
    "# paneldf = pd.read_excel(\"../panel_design/All_panel_designs_20250601.xlsx\", sheet_name=panel_name)\n",
    "# paneldf[f\"{genome_version}_org\"] = paneldf[genome_version].values\n",
    "# paneldf[\"lengthF\"] = paneldf[\"Forward Primer Seq\"].apply(lambda x: len(x))\n",
    "# paneldf[\"lengthR\"] = paneldf[\"Reverse Primer Seq\"].apply(lambda x: len(x))\n",
    "\n",
    "def _remove_primer_coords(x, lenF, lenR):\n",
    "    chrom = x.split(\":\")[0]\n",
    "    start = int(x.split(\":\")[1].split(\"-\")[0])\n",
    "    end = int(x.split(\":\")[1].split(\"-\")[1])\n",
    "    start = start + lenF - 1\n",
    "    end = end - lenR + 1\n",
    "    return f\"{chrom}:{start}-{end}\"\n",
    "\n",
    "def get_refseq(path_to_all_fa, chrom, start, end):\n",
    "        refseq = pyfaidx.Fasta(os.path.join(path_to_all_fa, \"{}.fa\".format(chrom)))\n",
    "        return(str.upper(refseq.get_seq(name = \"{}\".format(chrom), start = start, end = end).seq))\n",
    "\n",
    "path_to_all_fa = \"/home/hieunguyen/resources/hg19\"\n",
    "genome_version = \"hg19\"\n",
    "\n",
    "##### get list of all real cpg for this panel\n",
    "all_cpgdf = dict()\n",
    "all_cpgdf_with_primer = dict()\n",
    "for panel_name in final_umi_rundf.Panel_version.unique():\n",
    "    \n",
    "    panel_name = panel_name.replace(\" \", \"_\")\n",
    "    paneldf = pd.read_excel(\"../panel_design/All_panel_designs_20250601.xlsx\", sheet_name=panel_name)\n",
    "    paneldf[f\"{genome_version}_org\"] = paneldf[genome_version].values\n",
    "    paneldf[\"lengthF\"] = paneldf[\"Forward Primer Seq\"].apply(lambda x: len(x))\n",
    "    paneldf[\"lengthR\"] = paneldf[\"Reverse Primer Seq\"].apply(lambda x: len(x))\n",
    "    paneldf[genome_version] = paneldf[[genome_version, \"lengthF\", \"lengthR\"]].apply(lambda x:_remove_primer_coords(x[0], x[1], x[2]), axis = 1)\n",
    "\n",
    "    def generate_cpgdf(region_col, paneldf):\n",
    "        outputdf = pd.DataFrame()\n",
    "        print(f\"working on panel: {panel_name}, with {len(paneldf[region_col].unique())} regions\")\n",
    "        for region in paneldf[region_col].unique():\n",
    "            region_name = paneldf[paneldf[region_col] == region][\"Amplicon\"].values[0]\n",
    "            chrom = region.split(\":\")[0].replace(\"Chr\", \"chr\").replace(\"chr\", \"\")\n",
    "            start = int(region.split(\":\")[1].split(\"-\")[0])\n",
    "            end = int(region.split(\":\")[1].split(\"-\")[1])\n",
    "            refseq = pyfaidx.Fasta(os.path.join(path_to_all_fa, \"chr{}.fa\".format(chrom)))\n",
    "            refseq_at_region = str.upper(refseq.get_seq(name = \"chr{}\".format(chrom), start = start, end = end).seq)\n",
    "\n",
    "            all_cpg_in_cluster = [m.start(0) for m in re.finditer(\"CG\", refseq_at_region)]\n",
    "            cpg_coords = [f\"chr{chrom}:{item + start}-{item + start + 1}\" for item in all_cpg_in_cluster]\n",
    "\n",
    "            tmp_outputdf = pd.DataFrame(data = cpg_coords, columns = [\"CpG\"])\n",
    "            tmp_outputdf[\"region\"] = region\n",
    "            tmp_outputdf[\"region_name\"] = region_name\n",
    "            outputdf = pd.concat([outputdf, tmp_outputdf], axis = 0)\n",
    "        print(f\"outputdf shape after adding region {region}: {outputdf.shape}\")\n",
    "        return outputdf\n",
    "    \n",
    "    cpgdf = generate_cpgdf(genome_version, paneldf)\n",
    "    cpgdf_with_primer = generate_cpgdf(f\"{genome_version}_org\", paneldf)\n",
    "    \n",
    "    cpgdf = cpgdf[[\"region\", \"CpG\", \"region_name\"]]\n",
    "    all_cpgdf[panel_name] = cpgdf.copy()\n",
    "\n",
    "    cpgdf_with_primer = cpgdf_with_primer[[\"region\", \"CpG\", \"region_name\"]]\n",
    "    all_cpgdf_with_primer[panel_name] = cpgdf_with_primer.copy()\n",
    "\n",
    "\n",
    "# for i in all_cpgdf.keys():\n",
    "#     tmpdf1 = all_cpgdf[i].copy()\n",
    "#     tmpdf2 = all_cpgdf_with_primer[i].copy()\n",
    "#     assert tmpdf1.shape[0] == tmpdf2.shape[0], f\"Error: {i} cpgdf and cpgdf_with_primer have different number of rows\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502edd17",
   "metadata": {},
   "source": [
    "# PROCESSING COV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_cov(input_cov_file, panel_name, sampleid, outputdir):\n",
    "    os.system(f\"mkdir -p {outputdir}\")\n",
    "    if os.path.exists(input_cov_file) == False:\n",
    "        print(f\"Input coverage file {input_cov_file} does not exist, skipping...\")\n",
    "        covdf = pd.DataFrame(columns=[\"chrom\", \"start\", \"end\", \"meth_density\", \"countC\", \"countT\", \"seq\", \"strand\", \"CpG\", \"check_context\", \"amplicon\"])\n",
    "        status = \"File not available\"\n",
    "    else:\n",
    "        print(f\"Processing {input_cov_file} for panel {panel_name}...\")\n",
    "        # get list of CpG which are not in primer regions\n",
    "        cpgdf = all_cpgdf[panel_name]\n",
    "        covdf = pd.read_csv(input_cov_file, header = None, sep = \"\\t\")\n",
    "        covdf.columns = [\"chrom\", \"start\", \"end\", \"meth_density\", \"countC\", \"countT\"]\n",
    "        if covdf.shape[0] != 0:\n",
    "            covdf = covdf[covdf[\"chrom\"].isin([\"chrX\", \"chrY\", \"chrMT\"]) == False]\n",
    "            covdf = covdf[covdf[\"chrom\"].str.contains(\"chrUn\") == False]\n",
    "            covdf = covdf[covdf[\"chrom\"].str.contains(\"_\") == False]\n",
    "            covdf[\"seq\"] = covdf[[\"chrom\", \"start\"]].progress_apply(lambda x: get_refseq(path_to_all_fa= path_to_all_fa, \n",
    "                                                                    chrom = x[0], start = x[1], end = x[1] + 1), axis = 1)\n",
    "            covdf[\"strand\"] = covdf[\"seq\"].apply(lambda x: \"+\" if x != \"CG\" else \"-\")\n",
    "            covdf_raw = covdf.copy()\n",
    "            covdf[\"start\"] = covdf[[\"seq\", \"start\"]].apply(lambda x: x[1] + 1 if x[0] != \"CG\" else x[1], axis = 1)\n",
    "\n",
    "            covdf[\"chrom\"] = covdf[\"chrom\"].apply(lambda x: str(x))\n",
    "            covdf[\"CpG\"] = covdf[[\"chrom\", \"start\"]].apply(lambda x: f\"{str(x[0])}:{x[1]}-{x[1] + 1}\", axis = 1)\n",
    "            covdf[\"check_context\"] = covdf[\"CpG\"].apply(lambda x: \"CpG_context\" if x in cpgdf[\"CpG\"].values else \"False\")\n",
    "            covdf[\"amplicon\"] = covdf[\"CpG\"].apply(lambda x: cpgdf[cpgdf[\"CpG\"] == x][\"region_name\"].values[0] if x in cpgdf[\"CpG\"].values else \"NA\")\n",
    "            status = \"Processed\"\n",
    "        else:\n",
    "            print(f\"Coverage file {input_cov_file} is empty, skipping...\")\n",
    "            covdf = pd.DataFrame(columns=[\"chrom\", \"start\", \"end\", \"meth_density\", \"countC\", \"countT\", \"seq\", \"strand\", \"CpG\", \"check_context\", \"amplicon\"])\n",
    "            status = \"Empty file\"\n",
    "        covdf.to_excel(os.path.join(outputdir, f\"{sampleid}.xlsx\"))\n",
    "    return status, os.path.join(outputdir, f\"{sampleid}.xlsx\")\n",
    "\n",
    "# mode = \"UMI\"  # or \"ignore_UMI\" \n",
    "for mode in [\"UMI\", \"ignore_UMI\"]:\n",
    "    all_status = []\n",
    "    all_finished_path = []\n",
    "    for j in range(final_umi_rundf.shape[0]):\n",
    "        panel_name = final_umi_rundf.Panel_version.values[j].replace(\" \", \"_\")\n",
    "        run = final_umi_rundf.Run.values[j]\n",
    "        sampleid = final_umi_rundf.SampleID.values[j]\n",
    "        if mode == \"UMI\":\n",
    "            input_cov_file = final_umi_rundf.UMI_cov_file.values[j]\n",
    "        elif mode == \"ignore_UMI\":\n",
    "            input_cov_file = final_umi_rundf.nonUMI_cov_file.values[j]\n",
    "\n",
    "        outputdir = os.path.join(path_to_01_output, \"UMI_cov\", run, panel_name, mode)\n",
    "        status, output_cov_path = generate_cov(input_cov_file=input_cov_file, panel_name=panel_name, sampleid=sampleid, outputdir=outputdir)\n",
    "        all_status.append(status)\n",
    "        all_finished_path.append(output_cov_path)\n",
    "    final_umi_rundf[f\"{mode}_status\"] = all_status\n",
    "    final_umi_rundf[f\"{mode}_processed_cov\"] = all_finished_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_umi_rundf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc32e4",
   "metadata": {},
   "source": [
    "# Main analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026242e8",
   "metadata": {},
   "source": [
    "## Generate RUN cov file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"R7288\"\n",
    "\n",
    "all_inputs = final_umi_rundf[(final_umi_rundf[\"Run\"] == run) & (final_umi_rundf[\"UMI_status\"] == \"Processed\")]\n",
    "all_inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextflow_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
