{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d941f744",
   "metadata": {},
   "source": [
    "# Overview: checking metadata and samplesheet for all RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da652c79",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import pathlib\n",
    "import pysam\n",
    "import pyfaidx\n",
    "import warnings\n",
    "import re\n",
    "import argparse\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "main_outptudir = \"/workdir/outdir/pipeline_output\"\n",
    "umt_distance = 0\n",
    "analysis_output_version = \"20250614\"\n",
    "name = \"Vi\"\n",
    "\n",
    "path_to_main_output = os.path.join(main_outptudir, \"data_analysis\", name, analysis_output_version)\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\")\n",
    "os.system(f\"mkdir -p {path_to_01_output}\")\n",
    "\n",
    "rundf = pd.read_excel(\"../panel_design/All_panel_designs_20250601.xlsx\", sheet_name=\"Runs_tracking\")\n",
    "rundf.columns = [\"Run\", \"SampleID\", \"UMI\", \"Panel_version\", \"Name\", \"amplicon_name\", \"serial\"]\n",
    "\n",
    "umi_rundf = rundf[(rundf[\"UMI\"] == \"Yes\") & (rundf[\"Name\"] == name) ]\n",
    "\n",
    "collect_all_sample_sheets = [item for item in pathlib.Path(\"../experiments/\").glob(\"SampleSheet_batch_*.csv\")]\n",
    "\n",
    "samplesheet = pd.DataFrame()\n",
    "for file in collect_all_sample_sheets:\n",
    "    df = pd.read_csv(file, sep=\",\")\n",
    "    df[\"batch\"] = file.name.replace(\".csv\", \"\")\n",
    "    samplesheet = pd.concat([samplesheet, df], ignore_index=True)\n",
    "\n",
    "samplesheet.columns = [\"filename\", \"FASTQ1\", \"FASTQ2\", \"batch\"]\n",
    "samplesheet[\"Run\"] = samplesheet[\"FASTQ1\"].apply(lambda x: x.split(\"/\")[5] if x.split(\"/\")[5] != \"2025\" else x.split(\"/\")[6])\n",
    "samplesheet[\"SampleID\"] = samplesheet[\"filename\"].apply(lambda x: x.split(\"_\")[0].split(\"-\")[1])\n",
    "print(f\"All available runs: {\", \".join(sorted(samplesheet['Run'].unique()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80ab64",
   "metadata": {},
   "source": [
    "## Check if there is any missing FASTQ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_fastq = [item for item in umi_rundf.SampleID.unique() if item not in samplesheet.SampleID.unique()]\n",
    "\n",
    "umi_rundf[umi_rundf.SampleID.isin(missing_fastq)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb5f1b",
   "metadata": {},
   "source": [
    "## Match output paths to main metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5891c",
   "metadata": {},
   "source": [
    "since there is duplicated SampleID, we should merge labcode and Run together to make them unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(os.path.join(path_to_01_output, \"UMI_runs_tracking.xlsx\")) == False:\n",
    "    umi_rundf[\"uniqueID\"] = umi_rundf[[\"SampleID\", \"Run\"]].apply(lambda x: f\"{x[0]}_{x[1]}\", axis=1)\n",
    "    samplesheet[\"uniqueID\"] = samplesheet[[\"SampleID\", \"Run\"]].apply(lambda x: f\"{x[0]}_{x[1]}\", axis=1)\n",
    "\n",
    "    final_umi_rundf = umi_rundf.merge(samplesheet.drop([\"SampleID\", \"Run\"], axis = 1), left_on = \"uniqueID\", right_on = \"uniqueID\")\n",
    "    final_umi_rundf[\"UMI_cov_file\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(lambda x: os.path.join(\n",
    "        main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_COV\", f\"{x[1]}.connor_R1_bismark_bt2_pe.bedGraph.gz.bismark.zero.cov\"\n",
    "    ), axis = 1)\n",
    "    final_umi_rundf[\"nonUMI_cov_file\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(lambda x: os.path.join(\n",
    "        main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_COV\", f\"{x[1]}.CutAdapt_R1_bismark_bt2_pe.bedGraph.gz.bismark.zero.cov\"\n",
    "    ), axis = 1)\n",
    "\n",
    "    final_umi_rundf[\"check_UMI\"] = final_umi_rundf[\"UMI_cov_file\"].apply(lambda x: os.path.exists(x))\n",
    "    final_umi_rundf[\"check_nonUMI\"] = final_umi_rundf[\"nonUMI_cov_file\"].apply(lambda x: os.path.exists(x))\n",
    "\n",
    "    final_umi_rundf[\"unmapped_bam\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_ALIGNMENT_UNMAPPED_BAM\", f\"{x[1]}_R1.UMIprocessed_bismark_bt2_pe.bam\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"connor_annotated\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"CONNOR_UMI_OUTPUT\", f\"{x[1]}.connor.fully_annotated.bam\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"connor_fastq\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"CONNOR_UMI_OUTPUT\", f\"{x[1]}.connor_R1.fastq.gz\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"umi_bam\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_ALIGNMENT\", f\"{x[1]}.connor_R1_bismark_bt2_pe.sorted.bam\"), axis = 1\n",
    "    )\n",
    "    final_umi_rundf[\"non_umi_bam\"] = final_umi_rundf[[\"batch\", \"filename\"]].apply(\n",
    "        lambda x: os.path.join(main_outptudir, x[0], f\"UMT_DISTANCE_{umt_distance}\", \"BISMARK_ALIGNMENT\", f\"{x[1]}.CutAdapt_R1_bismark_bt2_pe.sorted.bam\"), axis = 1\n",
    "    )\n",
    "\n",
    "    tqdm.pandas()\n",
    "    for col in [\"unmapped_bam\", \"connor_annotated\", \"connor_fastq\", \"umi_bam\", \"non_umi_bam\" , \"UMI_cov_file\"]:\n",
    "        print(f\"working on column: {col}\")\n",
    "        def _get_line_count(x):\n",
    "            check_file = os.path.exists(x)\n",
    "            x_raw = x.replace(\".sorted.bam\", \".bam\")\n",
    "            if check_file == False:\n",
    "                if os.path.exists(x_raw) == True: \n",
    "                    # print(f\"sorted bam file is not available, but raw bam file is available, sorting and indexing it now...\")\n",
    "                    os.system(f\"samtools sort -@ 15 {x_raw} -o {x}\")\n",
    "                    os.system(f\"samtools index {x}\")\n",
    "                else:\n",
    "                    # rint(f\"File {x} does not exist, skipping line count for this file.\")\n",
    "                    return 0\n",
    "            if \".bam\" in x:\n",
    "                result = subprocess.run(f\"samtools view {x} -c\", shell=True, capture_output=True, text=True)\n",
    "            elif \".fastq.gz\" in x:\n",
    "                result = subprocess.run(f\"zcat {x} | wc -l\", shell=True, capture_output=True, text=True)\n",
    "            else:\n",
    "                result = subprocess.run(f\"cat {x} | wc -l\", shell=True, capture_output=True, text=True)\n",
    "            return int(result.stdout.strip())\n",
    "            \n",
    "        final_umi_rundf[f\"count_{col}\"] = final_umi_rundf[col].progress_apply(_get_line_count)    \n",
    "\n",
    "    final_umi_rundf.to_excel(os.path.join(path_to_01_output, \"UMI_runs_tracking.xlsx\"), index=False)\n",
    "else:\n",
    "    print(\"reading in saved processed UMI runs tracking file...\")\n",
    "    final_umi_rundf = pd.read_excel(os.path.join(path_to_01_output, \"UMI_runs_tracking.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f0dec",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refseq(path_to_all_fa, chrom, start, end):\n",
    "        refseq = pyfaidx.Fasta(os.path.join(path_to_all_fa, \"{}.fa\".format(chrom)))\n",
    "        return(str.upper(refseq.get_seq(name = \"{}\".format(chrom), start = start, end = end).seq))\n",
    "\n",
    "path_to_all_fa = \"/home/hieunguyen/resources/hg19\"\n",
    "genome_version = \"hg19\"\n",
    "\n",
    "##### get list of all real cpg for this panel\n",
    "all_cpgdf = dict()\n",
    "for panel_name in final_umi_rundf.Panel_version.unique():\n",
    "    cpgdf = pd.DataFrame()\n",
    "    panel_name = panel_name.replace(\" \", \"_\")\n",
    "    paneldf = pd.read_excel(\"../panel_design/All_panel_designs_20250601.xlsx\", sheet_name=panel_name)\n",
    "    for region in paneldf[genome_version].unique():\n",
    "        region_name = paneldf[paneldf[genome_version] == region][\"Amplicon\"].values[0]\n",
    "        chrom = region.split(\":\")[0].replace(\"Chr\", \"chr\").replace(\"chr\", \"\")\n",
    "        start = int(region.split(\":\")[1].split(\"-\")[0])\n",
    "        end = int(region.split(\":\")[1].split(\"-\")[1])\n",
    "        refseq = pyfaidx.Fasta(os.path.join(path_to_all_fa, \"chr{}.fa\".format(chrom)))\n",
    "        refseq_at_region = str.upper(refseq.get_seq(name = \"chr{}\".format(chrom), start = start, end = end).seq)\n",
    "\n",
    "        all_cpg_in_cluster = [m.start(0) for m in re.finditer(\"CG\", refseq_at_region)]\n",
    "        cpg_coords = [f\"chr{chrom}:{item + start}-{item + start + 1}\" for item in all_cpg_in_cluster]\n",
    "\n",
    "        tmp_cpgdf = pd.DataFrame(data = cpg_coords, columns = [\"CpG\"])\n",
    "        tmp_cpgdf[\"region\"] = region\n",
    "        tmp_cpgdf[\"region_name\"] = region_name\n",
    "        cpgdf = pd.concat([cpgdf, tmp_cpgdf], axis = 0)\n",
    "\n",
    "    cpgdf = cpgdf[[\"region\", \"CpG\", \"region_name\"]]\n",
    "    all_cpgdf[panel_name] = cpgdf.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502edd17",
   "metadata": {},
   "source": [
    "# PROCESSING COV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_cov(input_cov_file, panel_name, sampleid, outputdir):\n",
    "    os.system(f\"mkdir -p {outputdir}\")\n",
    "    if os.path.exists(input_cov_file) == False:\n",
    "        print(f\"Input coverage file {input_cov_file} does not exist, skipping...\")\n",
    "        covdf = pd.DataFrame(columns=[\"chrom\", \"start\", \"end\", \"meth_density\", \"countC\", \"countT\", \"seq\", \"strand\", \"CpG\", \"check_context\", \"amplicon\"])\n",
    "        status = \"File not available\"\n",
    "    else:\n",
    "        print(f\"Processing {input_cov_file} for panel {panel_name}...\")\n",
    "        cpgdf = all_cpgdf[panel_name]\n",
    "        covdf = pd.read_csv(input_cov_file, header = None, sep = \"\\t\")\n",
    "        covdf.columns = [\"chrom\", \"start\", \"end\", \"meth_density\", \"countC\", \"countT\"]\n",
    "        if covdf.shape[0] != 0:\n",
    "            covdf = covdf[covdf[\"chrom\"].isin([\"chrX\", \"chrY\", \"chrMT\"]) == False]\n",
    "            covdf = covdf[covdf[\"chrom\"].str.contains(\"chrUn\") == False]\n",
    "            covdf = covdf[covdf[\"chrom\"].str.contains(\"_\") == False]\n",
    "            covdf[\"seq\"] = covdf[[\"chrom\", \"start\"]].progress_apply(lambda x: get_refseq(path_to_all_fa= path_to_all_fa, \n",
    "                                                                    chrom = x[0], start = x[1], end = x[1] + 1), axis = 1)\n",
    "            covdf[\"strand\"] = covdf[\"seq\"].apply(lambda x: \"+\" if x != \"CG\" else \"-\")\n",
    "            covdf_raw = covdf.copy()\n",
    "            covdf[\"start\"] = covdf[[\"seq\", \"start\"]].apply(lambda x: x[1] + 1 if x[0] != \"CG\" else x[1], axis = 1)\n",
    "\n",
    "            covdf[\"chrom\"] = covdf[\"chrom\"].apply(lambda x: str(x))\n",
    "            covdf[\"CpG\"] = covdf[[\"chrom\", \"start\"]].apply(lambda x: f\"{str(x[0])}:{x[1]}-{x[1] + 1}\", axis = 1)\n",
    "            covdf[\"check_context\"] = covdf[\"CpG\"].apply(lambda x: \"CpG_context\" if x in cpgdf[\"CpG\"].values else \"False\")\n",
    "            covdf[\"amplicon\"] = covdf[\"CpG\"].apply(lambda x: cpgdf[cpgdf[\"CpG\"] == x][\"region_name\"].values[0] if x in cpgdf[\"CpG\"].values else \"NA\")\n",
    "            status = \"Processed\"\n",
    "        else:\n",
    "            print(f\"Coverage file {input_cov_file} is empty, skipping...\")\n",
    "            covdf = pd.DataFrame(columns=[\"chrom\", \"start\", \"end\", \"meth_density\", \"countC\", \"countT\", \"seq\", \"strand\", \"CpG\", \"check_context\", \"amplicon\"])\n",
    "            status = \"Empty file\"\n",
    "        covdf.to_excel(os.path.join(outputdir, f\"{sampleid}.xlsx\"))\n",
    "    return status\n",
    "\n",
    "# mode = \"UMI\"  # or \"ignore_UMI\" \n",
    "for mode in [\"UMI\", \"ignore_UMI\"]:\n",
    "    all_status = []\n",
    "    for j in range(final_umi_rundf.shape[0]):\n",
    "        panel_name = final_umi_rundf.Panel_version.values[j].replace(\" \", \"_\")\n",
    "        run = final_umi_rundf.Run.values[j]\n",
    "        sampleid = final_umi_rundf.SampleID.values[j]\n",
    "        if mode == \"UMI\":\n",
    "            input_cov_file = final_umi_rundf.UMI_cov_file.values[j]\n",
    "        elif mode == \"ignore_UMI\":\n",
    "            input_cov_file = final_umi_rundf.nonUMI_cov_file.values[j]\n",
    "\n",
    "        outputdir = os.path.join(path_to_01_output, \"UMI_cov\", run, panel_name, mode)\n",
    "        status = generate_cov(input_cov_file=input_cov_file, panel_name=panel_name, sampleid=sampleid, outputdir=outputdir)\n",
    "        all_status.append(status)\n",
    "    final_umi_rundf[f\"{mode}_status\"] = all_status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextflow_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
